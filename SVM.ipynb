{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiyuanWuSFU/CM-T310-Artificial-Intelligence-Survey/blob/master/SVM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtIoc4SJZSZs"
      },
      "source": [
        "This file is used to download Kaggle datasets into a personal Google Drive.\n",
        "In order to use this, we need a kaggle.json file, which contains the API credentials.\n",
        "To obtain a kaggle.json file, sign into your Kaggle account and go to your profile, then 'My Account'. Under the API section, click 'Create New API Token' to generate the kaggle.json file. Afterwards, save it in the same directory as this .ipynb file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7V6Iy1YHGc5"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_addons\n",
        "!pip install tensorflow --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TatOgQbEGqpp"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_addons as tfa\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "import joblib as job\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3F7gNtIb8UF-",
        "outputId": "1e20551f-fa37-4943-957a-3ed678ae12a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "dataset_df = pd.read_csv('/content/drive/MyDrive/9417project/train.csv')\n",
        "labels = pd.read_csv('/content/drive/MyDrive/9417project/train_labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_24CBsOTIfTd",
        "outputId": "4e9e87e0-8df6-43a1-ee5d-0eeb26206a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memory usage of dataframe is 4012.60 MB\n",
            "Memory usage became:  1028.2593326568604  MB\n"
          ]
        }
      ],
      "source": [
        "#Reduce Memory Usage\n",
        "def get_minimal_dtype(df):\n",
        "\n",
        "    start_mem = df.memory_usage().sum() / 1024**2\n",
        "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "\n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype.name\n",
        "        if ((col_type != 'datetime64[ns]') & (col_type != 'category')):\n",
        "            if (col_type != 'object'):\n",
        "                c_min = df[col].min()\n",
        "                c_max = df[col].max()\n",
        "\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                        df[col] = df[col].astype(np.int8)\n",
        "                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                        df[col] = df[col].astype(np.int16)\n",
        "                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                        df[col] = df[col].astype(np.int32)\n",
        "                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                        df[col] = df[col].astype(np.int64)\n",
        "\n",
        "                else:\n",
        "                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "                        df[col] = df[col].astype(np.float16)\n",
        "                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                        df[col] = df[col].astype(np.float32)\n",
        "                    else:\n",
        "                        pass\n",
        "            else:\n",
        "                df[col] = df[col].astype('category')\n",
        "    mem_usg = df.memory_usage().sum() / 1024**2\n",
        "    print(\"Memory usage became: \",mem_usg,\" MB\")\n",
        "\n",
        "    return df\n",
        "dataset_df = get_minimal_dtype(dataset_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uxJbdsU9u0Xd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2c1efda-4f6f-4994-aede-5ccfb37bb74e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full train dataset shape is (26296946, 20)\n"
          ]
        }
      ],
      "source": [
        "print(\"Full train dataset shape is {}\".format(dataset_df.shape))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8j1URVXwjI87"
      },
      "source": [
        "Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8VlcYpJ8jInI"
      },
      "outputs": [],
      "source": [
        "missing_values = dataset_df.isnull().sum()\n",
        "\n",
        "# Fill missing values\n",
        "dataset_df['page'].fillna(-1, inplace=True)\n",
        "dataset_df['room_coor_x'].fillna(-1, inplace=True)\n",
        "dataset_df['room_coor_y'].fillna(-1, inplace=True)\n",
        "dataset_df['screen_coor_x'].fillna(-1, inplace=True)\n",
        "dataset_df['screen_coor_y'].fillna(-1, inplace=True)\n",
        "dataset_df['hover_duration'].fillna(-1, inplace=True)\n",
        "\n",
        "# Cap 'elapsed_time' at the 99th percentile\n",
        "dataset_df['elapsed_time'] = dataset_df['elapsed_time'].clip(upper=dataset_df['elapsed_time'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vliYzKALwLww",
        "outputId": "2f37e71b-6c7e-42f8-def6-73cb05b19ac7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             session_id  correct            session  q\n",
              "0  20090312431273200_q1        1  20090312431273200  1\n",
              "1  20090312433251036_q1        0  20090312433251036  1\n",
              "2  20090312455206810_q1        1  20090312455206810  1\n",
              "3  20090313091715820_q1        0  20090313091715820  1\n",
              "4  20090313571836404_q1        1  20090313571836404  1"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-89089afd-54bc-45ce-af4e-eefa63197235\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session_id</th>\n",
              "      <th>correct</th>\n",
              "      <th>session</th>\n",
              "      <th>q</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20090312431273200_q1</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312431273200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20090312433251036_q1</td>\n",
              "      <td>0</td>\n",
              "      <td>20090312433251036</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>20090312455206810_q1</td>\n",
              "      <td>1</td>\n",
              "      <td>20090312455206810</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20090313091715820_q1</td>\n",
              "      <td>0</td>\n",
              "      <td>20090313091715820</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20090313571836404_q1</td>\n",
              "      <td>1</td>\n",
              "      <td>20090313571836404</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89089afd-54bc-45ce-af4e-eefa63197235')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-1ab8daa8-a49b-48e6-abec-edc1418d1089\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1ab8daa8-a49b-48e6-abec-edc1418d1089')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-1ab8daa8-a49b-48e6-abec-edc1418d1089 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-89089afd-54bc-45ce-af4e-eefa63197235 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-89089afd-54bc-45ce-af4e-eefa63197235');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "labels['session'] = labels.session_id.apply(lambda x: int(x.split('_')[0]) )\n",
        "labels['q'] = labels.session_id.apply(lambda x: int(x.split('_')[-1][1:]) )\n",
        "labels.head(5)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qPzqthNkrNe"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 30))\n",
        "plt.subplots_adjust(hspace=0.5, wspace=0.5)\n",
        "for n in range(1,19):\n",
        "    #print(n, str(n))\n",
        "    ax = plt.subplot(6, 3, n)\n",
        "\n",
        "    # filter df and plot ticker on the new subplot axis\n",
        "    plot_df = labels.loc[labels.q == n]\n",
        "    plot_df = plot_df.correct.value_counts()\n",
        "    plot_df.plot(ax=ax, kind=\"bar\", color=['b', 'c'])\n",
        "\n",
        "    # chart formatting\n",
        "    ax.set_title(\"Question \" + str(n))\n",
        "    ax.set_xlabel(\"\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Distribution.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz9WQne5S85d",
        "outputId": "3b3ffe38-accd-47e3-89f6-1d517396f089"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full label dataset shape is (424116, 4)\n"
          ]
        }
      ],
      "source": [
        "print(\"Full label dataset shape is {}\".format(labels.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDYrO-S0R3eD"
      },
      "source": [
        "Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HecR2WqVAkAX"
      },
      "outputs": [],
      "source": [
        "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
        "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y',\n",
        "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "def feature_engineer(dataset_df):\n",
        "    dfs = []\n",
        "    for c in CATEGORICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
        "        tmp.name = tmp.name + '_nunique'\n",
        "        dfs.append(tmp)\n",
        "    for c in NUMERICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
        "        dfs.append(tmp)\n",
        "    for c in NUMERICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
        "        tmp.name = tmp.name + '_std'\n",
        "        dfs.append(tmp)\n",
        "    dataset_df = pd.concat(dfs,axis=1)\n",
        "    dataset_df = dataset_df.fillna(-1)\n",
        "    dataset_df = dataset_df.reset_index()\n",
        "    dataset_df = dataset_df.set_index('session_id')\n",
        "    return dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKnTJdRLA0a-"
      },
      "outputs": [],
      "source": [
        "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
        "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y',\n",
        "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "BINNING = ['elapsed_time', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "\n",
        "# Define feature engineering function\n",
        "def feature_engineer_ver2(dataset_df):\n",
        "    dfs = []\n",
        "    for c in CATEGORICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
        "        tmp.name = c + '_nunique'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    for c in NUMERICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
        "        tmp.name = c + '_mean'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "        # Compute standard deviation only for certain features\n",
        "        if c in BINNING:\n",
        "            tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
        "            tmp.name = c + '_std'\n",
        "            dfs.append(tmp)\n",
        "\n",
        "        # Binning\n",
        "        if c in BINNING:  # Check if column is in the list of columns to bin\n",
        "            dataset_df[c+'_bin'] = pd.qcut(dataset_df[c], q=4, duplicates='drop')\n",
        "            tmp = dataset_df.groupby(['session_id','level_group'])[c+'_bin'].agg('count')\n",
        "            tmp.name = c + '_bin_count'\n",
        "            dfs.append(tmp)\n",
        "\n",
        "    # Interaction between screen coordinates\n",
        "    if 'screen_coor_x' in NUMERICAL and 'screen_coor_y' in NUMERICAL:\n",
        "        # Compute Euclidean distance instead of product\n",
        "        dataset_df['screen_coor'] = np.sqrt(dataset_df['screen_coor_x']**2 + dataset_df['screen_coor_y']**2)\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['screen_coor'].agg(['mean', 'std'])\n",
        "        tmp.columns = ['screen_coor_mean', 'screen_coor_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    # Aggregated features\n",
        "    if 'hover_duration' in NUMERICAL:\n",
        "        dataset_df['total_hover_duration'] = dataset_df.groupby(['session_id'])['hover_duration'].transform('sum')\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['total_hover_duration'].agg('mean')\n",
        "        tmp.name = 'total_hover_duration_mean'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    dataset_df = pd.concat(dfs,axis=1)\n",
        "    dataset_df = dataset_df.fillna(-1)\n",
        "    dataset_df = dataset_df.reset_index()\n",
        "    dataset_df = dataset_df.set_index('session_id')\n",
        "    return dataset_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Phrh-o1Sj-7D"
      },
      "outputs": [],
      "source": [
        "CATEGORICAL = ['event_name', 'name','fqid', 'room_fqid', 'text_fqid']\n",
        "NUMERICAL = ['elapsed_time','level','page','room_coor_x', 'room_coor_y',\n",
        "        'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "BINNING = ['elapsed_time', 'room_coor_x', 'room_coor_y', 'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "\n",
        "from sklearn.preprocessing import PowerTransformer\n",
        "\n",
        "def feature_engineer_ver3(dataset_df):\n",
        "    dfs = []\n",
        "    pt = PowerTransformer(method='yeo-johnson')\n",
        "\n",
        "    for c in CATEGORICAL:\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('nunique')\n",
        "        tmp.name = c + '_nunique'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "        # Create dummy variables for top N most common events and names\n",
        "        top_N = dataset_df[c].value_counts()[:10].index\n",
        "        for val in top_N:\n",
        "            dataset_df[c + '_' + val] = (dataset_df[c] == val).astype(int)\n",
        "        tmp = dataset_df.groupby(['session_id','level_group']).agg({c + '_' + val: 'sum' for val in top_N})\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    for c in NUMERICAL:\n",
        "        # Fill missing values with the column median\n",
        "        dataset_df[c].fillna(dataset_df[c].median(), inplace=True)\n",
        "\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('mean')\n",
        "        tmp.name = c + '_mean'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "        # Compute standard deviation only for certain features\n",
        "        if c in BINNING:\n",
        "            tmp = dataset_df.groupby(['session_id','level_group'])[c].agg('std')\n",
        "            tmp.name = c + '_std'\n",
        "            dfs.append(tmp)\n",
        "\n",
        "        # Normalize 'elapsed_time' column\n",
        "        if c == 'elapsed_time':\n",
        "            dataset_df[c] = pt.fit_transform(dataset_df[[c]])\n",
        "\n",
        "        # Binning\n",
        "        if c in BINNING:  # Check if column is in the list of columns to bin\n",
        "            dataset_df[c+'_bin'] = pd.qcut(dataset_df[c], q=4, duplicates='drop')\n",
        "            tmp = dataset_df.groupby(['session_id','level_group'])[c+'_bin'].agg('count')\n",
        "            tmp.name = c + '_bin_count'\n",
        "            dfs.append(tmp)\n",
        "\n",
        "    # Interaction between screen coordinates\n",
        "    if 'screen_coor_x' in NUMERICAL and 'screen_coor_y' in NUMERICAL:\n",
        "        # Compute Euclidean distance instead of product\n",
        "        dataset_df['screen_coor'] = np.sqrt(dataset_df['screen_coor_x']**2 + dataset_df['screen_coor_y']**2)\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['screen_coor'].agg(['mean', 'std'])\n",
        "        tmp.columns = ['screen_coor_mean', 'screen_coor_std']\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    # Aggregated features\n",
        "    if 'hover_duration' in NUMERICAL:\n",
        "        dataset_df['total_hover_duration'] = dataset_df.groupby(['session_id'])['hover_duration'].transform('sum')\n",
        "        tmp = dataset_df.groupby(['session_id','level_group'])['total_hover_duration'].agg('mean')\n",
        "        tmp.name = 'total_hover_duration_mean'\n",
        "        dfs.append(tmp)\n",
        "\n",
        "    dataset_df = pd.concat(dfs, axis=1)\n",
        "    dataset_df = dataset_df.fillna(-1)\n",
        "    dataset_df = dataset_df.reset_index()\n",
        "    dataset_df = dataset_df.set_index('session_id')\n",
        "\n",
        "    return dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A11AvSWEkNOl"
      },
      "outputs": [],
      "source": [
        "CATEGORICAL = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
        "NUMERICAL = ['elapsed_time', 'level', 'page', 'room_coor_x', 'room_coor_y',\n",
        "             'screen_coor_x', 'screen_coor_y', 'hover_duration']\n",
        "\n",
        "def feature_engineer_ver4(dataset_df):\n",
        "    # Impute missing values\n",
        "    # For numerical features use median\n",
        "    for c in NUMERICAL:\n",
        "        dataset_df[c].fillna(dataset_df[c].median(), inplace=True)\n",
        "\n",
        "    # For categorical features use mode\n",
        "    for c in CATEGORICAL:\n",
        "        dataset_df[c].fillna(dataset_df[c].mode()[0], inplace=True)\n",
        "\n",
        "    # Frequency encoding for 'event_name' and 'fqid'\n",
        "    for c in ['event_name', 'fqid']:\n",
        "        freq_encoding = dataset_df[c].value_counts(normalize=True)\n",
        "        dataset_df[c + '_freq'] = dataset_df[c].map(freq_encoding)\n",
        "\n",
        "    # Aggregate features for each session\n",
        "    agg_features = dataset_df.groupby('session_id')[NUMERICAL].agg(['mean', 'sum', 'std'])\n",
        "    agg_features.columns = ['_'.join(col).strip() for col in agg_features.columns.values]\n",
        "    dataset_df = pd.merge(dataset_df, agg_features, on='session_id', how='left')\n",
        "\n",
        "    # Interaction features\n",
        "    dataset_df['screen_coor_interaction'] = dataset_df['screen_coor_x'] * dataset_df['screen_coor_y']\n",
        "    dataset_df['level_page_interaction'] = dataset_df['level'] * dataset_df['page']\n",
        "\n",
        "    # Frequency encoding for 'name', 'room_fqid', and 'text_fqid'\n",
        "    for c in ['name', 'room_fqid', 'text_fqid']:\n",
        "        freq_encoding = dataset_df[c].value_counts(normalize=True)\n",
        "        dataset_df[c + '_freq'] = dataset_df[c].map(freq_encoding)\n",
        "    dataset_df = dataset_df.drop(columns=['event_name'])\n",
        "    dataset_df = dataset_df.drop(columns=['name'])\n",
        "    dataset_df = dataset_df.reset_index()\n",
        "    dataset_df = dataset_df.set_index('session_id')\n",
        "    return dataset_df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def feature_engineer_ver5(data):\n",
        "    # Encode categorical variables\n",
        "    categorical_cols = ['event_name', 'name', 'fqid', 'room_fqid', 'text_fqid']\n",
        "    encoder = LabelEncoder()\n",
        "    for col in categorical_cols:\n",
        "        data[col] = encoder.fit_transform(data[col])\n",
        "\n",
        "    # Generate historical features\n",
        "    # Here we calculate the average elapsed_time for all previous events in the same session\n",
        "    data['avg_elapsed_time'] = data.groupby('session_id')['elapsed_time'].transform('mean')\n",
        "\n",
        "    # You can add more historical features as needed\n",
        "    # For example, count the number of 'navigate_click' events for each session\n",
        "    data['navigate_click_count'] = data[data['event_name'] == 'navigate_click'].groupby('session_id')['event_name'].transform('count')\n",
        "\n",
        "    # Or calculate the maximum hover_duration for each session\n",
        "    data['max_hover_duration'] = data.groupby('session_id')['hover_duration'].transform('max')\n",
        "    # Count of each event type\n",
        "    event_counts = data.groupby('session_id')['event_name'].value_counts().unstack(fill_value=0)\n",
        "    data = data.join(event_counts, on='session_id')\n",
        "\n",
        "    # Time since the last event\n",
        "    data['time_since_last_event'] = data.groupby('session_id')['elapsed_time'].diff()\n",
        "\n",
        "    # Number of events in fullscreen mode\n",
        "    data['fullscreen_event_count'] = data[data['fullscreen'] == 1].groupby('session_id')['fullscreen'].transform('count')\n",
        "\n",
        "    # Number of events with music on\n",
        "    data['music_event_count'] = data[data['music'] == 1].groupby('session_id')['music'].transform('count')\n",
        "\n",
        "    # Number of unique levels played\n",
        "    data['unique_levels_count'] = data.groupby('session_id')['level'].transform('nunique')\n",
        "\n",
        "    return data"
      ],
      "metadata": {
        "id": "6ivW1QOZbbbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "4GWkJpO64xTF"
      },
      "outputs": [],
      "source": [
        "# loading data by chunck to avoid mem running out\n",
        "def partial_loader(df):\n",
        "  split = 5\n",
        "  epoch_length = df.shape[0]//split\n",
        "  start = 0\n",
        "  partial_df = df.iloc[start:start+epoch_length].copy(deep = True)\n",
        "  partial_df = feature_engineer_ver3(partial_df)\n",
        "  start += epoch_length\n",
        "  for i in range(split - 2):\n",
        "    partial_df = pd.concat([partial_df,feature_engineer_ver3(df.iloc[start:start+epoch_length].copy(deep = True))])\n",
        "    start += epoch_length\n",
        "  partial_df = pd.concat([partial_df,feature_engineer_ver3(df.iloc[start:])])\n",
        "  return partial_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yE9dMsXYA5J2"
      },
      "outputs": [],
      "source": [
        "# select different version of feature engineer here\n",
        "\n",
        "#dataset_df = feature_engineer(dataset_df)\n",
        "#dataset_df = feature_engineer_ver2(dataset_df)\n",
        "dataset_df = partial_loader(dataset_df)\n",
        "#dataset_df = feature_engineer_ver4(dataset_df)\n",
        "print(\"Full prepared dataset shape is {}\".format(dataset_df.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGuCeo8Ff1p7"
      },
      "source": [
        "SVM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "NuwWFOtW8plx"
      },
      "outputs": [],
      "source": [
        "# Create max_sub_model sub models, regular svm model if max_sub_model is equal to 1\n",
        "def train_sub_models(train_df,train_users,train_labels,q_no):\n",
        "  seed_value = 42\n",
        "  max_countrol = False\n",
        "  max_sub_model = 1\n",
        "\n",
        "  print(train_labels.correct.value_counts())\n",
        "\n",
        "\n",
        "  label_1 = train_labels.loc[train_labels.correct == 1 ]\n",
        "  label_0 = train_labels.loc[train_labels.correct == 0 ]\n",
        "  label_0_train_data = train_df[train_df.index.isin(label_0.index.values)]\n",
        "  label_1_train_data = train_df[train_df.index.isin(label_1.index.values)]\n",
        "\n",
        "  num_of_submodel = label_1.shape[0]//label_0.shape[0]\n",
        "  if num_of_submodel > max_sub_model:\n",
        "    num_of_submodel = max_sub_model\n",
        "    max_countrol = True\n",
        "  start = 0\n",
        "  if num_of_submodel == 0:\n",
        "    num_of_submodel = 1\n",
        "  for i in range(num_of_submodel-1):\n",
        "    model = SVC(probability=True)\n",
        "    if max_countrol:\n",
        "      split_label = label_1.iloc[start:start+label_1.shape[0]//(num_of_submodel)]\n",
        "      concat_label = pd.concat([split_label,label_0])\n",
        "      shuffled_label = concat_label.sample(frac=1, random_state=seed_value)\n",
        "      shuffled_label = shuffled_label['correct']\n",
        "\n",
        "      split_data = label_1_train_data.iloc[start:start+label_1_train_data.shape[0]//(num_of_submodel)]\n",
        "      concat_data = pd.concat([split_data,label_0_train_data])\n",
        "      shuffled_data = concat_data.sample(frac=1, random_state=seed_value)\n",
        "      print(split_label.shape)\n",
        "      model.fit(shuffled_data,shuffled_label)\n",
        "      file_path = f'/content/drive/MyDrive/9417project/models/SVM_models/model_{grp}_{q_no}_sub{i}.joblib'\n",
        "      job.dump(model,file_path)\n",
        "      start = start + label_1.shape[0]//(num_of_submodel)\n",
        "    else:\n",
        "      split_label = label_1.iloc[start:start+label_0.shape[0]]\n",
        "      concat_label = pd.concat([split_label,label_0])\n",
        "      shuffled_label = concat_label.sample(frac=1, random_state=seed_value)\n",
        "      shuffled_label = shuffled_label['correct']\n",
        "      print(split_label.shape)\n",
        "\n",
        "      split_data = label_1_train_data.iloc[start:start+label_0_train_data.shape[0]]\n",
        "      concat_data = pd.concat([split_data,label_0_train_data])\n",
        "      shuffled_data = concat_data.sample(frac=1, random_state=seed_value)\n",
        "\n",
        "      model.fit(shuffled_data,shuffled_label)\n",
        "      file_path = f'/content/drive/MyDrive/9417project/models/SVM_models/model_{grp}_{q_no}_sub{i}.joblib'\n",
        "      job.dump(model,file_path)\n",
        "      start = start + label_0.shape[0]\n",
        "\n",
        "\n",
        "  split_label = label_1.iloc[start:]\n",
        "  concat_label = pd.concat([split_label,label_0])\n",
        "  shuffled_label = concat_label.sample(frac=1, random_state=seed_value)\n",
        "  shuffled_label = shuffled_label['correct']\n",
        "\n",
        "  split_data = label_1_train_data.iloc[start:]\n",
        "  concat_data = pd.concat([split_data,label_0_train_data])\n",
        "  shuffled_data = concat_data.sample(frac=1, random_state=seed_value)\n",
        "\n",
        "  model = SVC(probability=True)\n",
        "\n",
        "  model.fit(shuffled_data,shuffled_label)\n",
        "  file_path = f'/content/drive/MyDrive/9417project/models/SVM_models/model_{grp}_{q_no}_sub{num_of_submodel-1}.joblib'\n",
        "\n",
        "  job.dump(model,file_path)\n",
        "\n",
        "  return num_of_submodel\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvY0TInWDSk0",
        "outputId": "6c1ef4ff-7fc2-4f6f-de8e-c883971a352e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### q_no 1 grp 0-4\n",
            "1    5581\n",
            "0    2211\n",
            "Name: correct, dtype: int64\n",
            "### q_no 2 grp 0-4\n",
            "1    7640\n",
            "0     152\n",
            "Name: correct, dtype: int64\n",
            "### q_no 3 grp 0-4\n",
            "1    7266\n",
            "0     526\n",
            "Name: correct, dtype: int64\n",
            "### q_no 4 grp 5-12\n",
            "1    6164\n",
            "0    1628\n",
            "Name: correct, dtype: int64\n",
            "### q_no 5 grp 5-12\n",
            "1    4164\n",
            "0    3628\n",
            "Name: correct, dtype: int64\n",
            "### q_no 6 grp 5-12\n",
            "1    5954\n",
            "0    1838\n",
            "Name: correct, dtype: int64\n",
            "### q_no 7 grp 5-12\n",
            "1    5635\n",
            "0    2157\n",
            "Name: correct, dtype: int64\n",
            "### q_no 8 grp 5-12\n",
            "1    4693\n",
            "0    3099\n",
            "Name: correct, dtype: int64\n",
            "### q_no 9 grp 5-12\n",
            "1    5627\n",
            "0    2165\n",
            "Name: correct, dtype: int64\n",
            "### q_no 10 grp 5-12\n",
            "0    3905\n",
            "1    3887\n",
            "Name: correct, dtype: int64\n",
            "### q_no 11 grp 5-12\n",
            "1    4980\n",
            "0    2812\n",
            "Name: correct, dtype: int64\n",
            "### q_no 12 grp 5-12\n",
            "1    6685\n",
            "0    1107\n",
            "Name: correct, dtype: int64\n",
            "### q_no 13 grp 5-12\n",
            "0    5708\n",
            "1    2084\n",
            "Name: correct, dtype: int64\n",
            "### q_no 14 grp 13-22\n",
            "1    5374\n",
            "0    2418\n",
            "Name: correct, dtype: int64\n",
            "### q_no 15 grp 13-22\n",
            "0    4113\n",
            "1    3679\n",
            "Name: correct, dtype: int64\n",
            "### q_no 16 grp 13-22\n",
            "1    5677\n",
            "0    2115\n",
            "Name: correct, dtype: int64\n",
            "### q_no 17 grp 13-22\n",
            "1    5275\n",
            "0    2517\n",
            "Name: correct, dtype: int64\n",
            "### q_no 18 grp 13-22\n",
            "1    7400\n",
            "0     392\n",
            "Name: correct, dtype: int64\n",
            "threshold  0.6700000000000003 \tF1 score  0.6511291\n",
            "### q_no 1 grp 0-4\n",
            "1    5582\n",
            "0    2212\n",
            "Name: correct, dtype: int64\n",
            "### q_no 2 grp 0-4\n",
            "1    7640\n",
            "0     154\n",
            "Name: correct, dtype: int64\n",
            "### q_no 3 grp 0-4\n",
            "1    7268\n",
            "0     526\n",
            "Name: correct, dtype: int64\n",
            "### q_no 4 grp 5-12\n",
            "1    6165\n",
            "0    1629\n",
            "Name: correct, dtype: int64\n",
            "### q_no 5 grp 5-12\n",
            "1    4163\n",
            "0    3631\n",
            "Name: correct, dtype: int64\n",
            "### q_no 6 grp 5-12\n",
            "1    5951\n",
            "0    1843\n",
            "Name: correct, dtype: int64\n",
            "### q_no 7 grp 5-12\n",
            "1    5642\n",
            "0    2152\n",
            "Name: correct, dtype: int64\n",
            "### q_no 8 grp 5-12\n",
            "1    4683\n",
            "0    3111\n",
            "Name: correct, dtype: int64\n",
            "### q_no 9 grp 5-12\n",
            "1    5628\n",
            "0    2166\n",
            "Name: correct, dtype: int64\n",
            "### q_no 10 grp 5-12\n",
            "0    3912\n",
            "1    3882\n",
            "Name: correct, dtype: int64\n",
            "### q_no 11 grp 5-12\n",
            "1    4983\n",
            "0    2811\n",
            "Name: correct, dtype: int64\n",
            "### q_no 12 grp 5-12\n",
            "1    6688\n",
            "0    1106\n",
            "Name: correct, dtype: int64\n",
            "### q_no 13 grp 5-12\n",
            "0    5709\n",
            "1    2085\n",
            "Name: correct, dtype: int64\n",
            "### q_no 14 grp 13-22\n",
            "1    5382\n",
            "0    2412\n",
            "Name: correct, dtype: int64\n",
            "### q_no 15 grp 13-22\n",
            "0    4114\n",
            "1    3680\n",
            "Name: correct, dtype: int64\n",
            "### q_no 16 grp 13-22\n",
            "1    5671\n",
            "0    2123\n",
            "Name: correct, dtype: int64\n",
            "### q_no 17 grp 13-22\n",
            "1    5276\n",
            "0    2518\n",
            "Name: correct, dtype: int64\n",
            "### q_no 18 grp 13-22\n",
            "1    7402\n",
            "0     392\n",
            "Name: correct, dtype: int64\n",
            "threshold  0.6400000000000002 \tF1 score  0.6490644\n",
            "### q_no 1 grp 0-4\n",
            "1    5585\n",
            "0    2212\n",
            "Name: correct, dtype: int64\n",
            "### q_no 2 grp 0-4\n",
            "1    7645\n",
            "0     152\n",
            "Name: correct, dtype: int64\n",
            "### q_no 3 grp 0-4\n",
            "1    7267\n",
            "0     530\n",
            "Name: correct, dtype: int64\n",
            "### q_no 4 grp 5-12\n",
            "1    6165\n",
            "0    1632\n",
            "Name: correct, dtype: int64\n",
            "### q_no 5 grp 5-12\n",
            "1    4160\n",
            "0    3637\n",
            "Name: correct, dtype: int64\n",
            "### q_no 6 grp 5-12\n",
            "1    5957\n",
            "0    1840\n",
            "Name: correct, dtype: int64\n",
            "### q_no 7 grp 5-12\n",
            "1    5642\n",
            "0    2155\n",
            "Name: correct, dtype: int64\n",
            "### q_no 8 grp 5-12\n",
            "1    4692\n",
            "0    3105\n",
            "Name: correct, dtype: int64\n",
            "### q_no 9 grp 5-12\n",
            "1    5631\n",
            "0    2166\n",
            "Name: correct, dtype: int64\n",
            "### q_no 10 grp 5-12\n",
            "0    3911\n",
            "1    3886\n",
            "Name: correct, dtype: int64\n",
            "### q_no 11 grp 5-12\n",
            "1    4980\n",
            "0    2817\n",
            "Name: correct, dtype: int64\n",
            "### q_no 12 grp 5-12\n",
            "1    6689\n",
            "0    1108\n",
            "Name: correct, dtype: int64\n",
            "### q_no 13 grp 5-12\n",
            "0    5716\n",
            "1    2081\n",
            "Name: correct, dtype: int64\n",
            "### q_no 14 grp 13-22\n",
            "1    5385\n",
            "0    2412\n",
            "Name: correct, dtype: int64\n",
            "### q_no 15 grp 13-22\n",
            "0    4118\n",
            "1    3679\n",
            "Name: correct, dtype: int64\n",
            "### q_no 16 grp 13-22\n",
            "1    5678\n",
            "0    2119\n",
            "Name: correct, dtype: int64\n",
            "### q_no 17 grp 13-22\n",
            "1    5276\n",
            "0    2521\n",
            "Name: correct, dtype: int64\n",
            "### q_no 18 grp 13-22\n",
            "1    7404\n",
            "0     393\n",
            "Name: correct, dtype: int64\n",
            "threshold  0.6400000000000002 \tF1 score  0.64992005\n",
            "### q_no 1 grp 0-4\n",
            "1    5581\n",
            "0    2207\n",
            "Name: correct, dtype: int64\n",
            "### q_no 2 grp 0-4\n",
            "1    7636\n",
            "0     152\n",
            "Name: correct, dtype: int64\n",
            "### q_no 3 grp 0-4\n",
            "1    7258\n",
            "0     530\n",
            "Name: correct, dtype: int64\n",
            "### q_no 4 grp 5-12\n",
            "1    6155\n",
            "0    1633\n",
            "Name: correct, dtype: int64\n",
            "### q_no 5 grp 5-12\n",
            "1    4160\n",
            "0    3628\n",
            "Name: correct, dtype: int64\n",
            "### q_no 6 grp 5-12\n",
            "1    5944\n",
            "0    1844\n",
            "Name: correct, dtype: int64\n",
            "### q_no 7 grp 5-12\n",
            "1    5631\n",
            "0    2157\n",
            "Name: correct, dtype: int64\n",
            "### q_no 8 grp 5-12\n",
            "1    4680\n",
            "0    3108\n",
            "Name: correct, dtype: int64\n",
            "### q_no 9 grp 5-12\n",
            "1    5625\n",
            "0    2163\n",
            "Name: correct, dtype: int64\n",
            "### q_no 10 grp 5-12\n",
            "0    3910\n",
            "1    3878\n",
            "Name: correct, dtype: int64\n",
            "### q_no 11 grp 5-12\n",
            "1    4978\n",
            "0    2810\n",
            "Name: correct, dtype: int64\n",
            "### q_no 12 grp 5-12\n",
            "1    6675\n",
            "0    1113\n",
            "Name: correct, dtype: int64\n",
            "### q_no 13 grp 5-12\n",
            "0    5708\n",
            "1    2080\n",
            "Name: correct, dtype: int64\n",
            "### q_no 14 grp 13-22\n",
            "1    5376\n",
            "0    2412\n",
            "Name: correct, dtype: int64\n",
            "### q_no 15 grp 13-22\n",
            "0    4114\n",
            "1    3674\n",
            "Name: correct, dtype: int64\n",
            "### q_no 16 grp 13-22\n",
            "1    5671\n",
            "0    2117\n",
            "Name: correct, dtype: int64\n",
            "### q_no 17 grp 13-22\n",
            "1    5266\n",
            "0    2522\n",
            "Name: correct, dtype: int64\n",
            "### q_no 18 grp 13-22\n",
            "1    7395\n",
            "0     393\n",
            "Name: correct, dtype: int64\n",
            "threshold  0.6500000000000002 \tF1 score  0.65104496\n",
            "### q_no 1 grp 0-4\n",
            "1    5573\n",
            "0    2210\n",
            "Name: correct, dtype: int64\n",
            "### q_no 2 grp 0-4\n",
            "1    7633\n",
            "0     150\n",
            "Name: correct, dtype: int64\n",
            "### q_no 3 grp 0-4\n",
            "1    7255\n",
            "0     528\n",
            "Name: correct, dtype: int64\n",
            "### q_no 4 grp 5-12\n",
            "1    6156\n",
            "0    1627\n",
            "Name: correct, dtype: int64\n",
            "### q_no 5 grp 5-12\n",
            "1    4157\n",
            "0    3626\n",
            "Name: correct, dtype: int64\n",
            "### q_no 6 grp 5-12\n",
            "1    5945\n",
            "0    1838\n",
            "Name: correct, dtype: int64\n",
            "### q_no 7 grp 5-12\n",
            "1    5632\n",
            "0    2151\n",
            "Name: correct, dtype: int64\n",
            "### q_no 8 grp 5-12\n",
            "1    4684\n",
            "0    3099\n",
            "Name: correct, dtype: int64\n",
            "### q_no 9 grp 5-12\n",
            "1    5618\n",
            "0    2165\n",
            "Name: correct, dtype: int64\n",
            "### q_no 10 grp 5-12\n",
            "0    3903\n",
            "1    3880\n",
            "Name: correct, dtype: int64\n",
            "### q_no 11 grp 5-12\n",
            "1    4968\n",
            "0    2815\n",
            "Name: correct, dtype: int64\n",
            "### q_no 12 grp 5-12\n",
            "1    6671\n",
            "0    1112\n",
            "Name: correct, dtype: int64\n",
            "### q_no 13 grp 5-12\n",
            "0    5703\n",
            "1    2080\n",
            "Name: correct, dtype: int64\n",
            "### q_no 14 grp 13-22\n",
            "1    5373\n",
            "0    2410\n",
            "Name: correct, dtype: int64\n",
            "### q_no 15 grp 13-22\n",
            "0    4113\n",
            "1    3670\n",
            "Name: correct, dtype: int64\n",
            "### q_no 16 grp 13-22\n",
            "1    5665\n",
            "0    2118\n",
            "Name: correct, dtype: int64\n",
            "### q_no 17 grp 13-22\n",
            "1    5270\n",
            "0    2513\n",
            "Name: correct, dtype: int64\n",
            "### q_no 18 grp 13-22\n",
            "1    7392\n",
            "0     391\n",
            "Name: correct, dtype: int64\n",
            "threshold  0.6400000000000002 \tF1 score  0.6476644\n"
          ]
        }
      ],
      "source": [
        "# model training using cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "# select number of folds for cv\n",
        "k_fold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "for train_indices, test_indices in k_fold.split(dataset_df.index.unique()):\n",
        "  train_users, valid_users = dataset_df.index[train_indices], dataset_df.index[test_indices]\n",
        "  train_x = dataset_df[dataset_df.index.isin(train_users)]\n",
        "  valid_x = dataset_df[dataset_df.index.isin(valid_users)]\n",
        "  model_per_question = []\n",
        "  VALID_USER_LIST = valid_x.index.unique()\n",
        "\n",
        "\n",
        "  prediction_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
        "\n",
        "\n",
        "  for q_no in range(1,19):\n",
        "\n",
        "      # Select level group for the question based on the q_no.\n",
        "      if q_no<=3: grp = '0-4'\n",
        "      elif q_no<=13: grp = '5-12'\n",
        "      elif q_no<=22: grp = '13-22'\n",
        "      print(\"### q_no\", q_no, \"grp\", grp)\n",
        "\n",
        "\n",
        "      # Filter the rows in the datasets based on the selected level group.\n",
        "      train_df = train_x.loc[train_x.level_group == grp]\n",
        "      train_users = train_df.index.values\n",
        "      valid_df = valid_x.loc[valid_x.level_group == grp]\n",
        "      valid_users = valid_df.index.values\n",
        "\n",
        "      # Drop the 'correct' and 'level_group' columns from the features\n",
        "      train_df = train_df.drop(columns=[\"level_group\"])\n",
        "      valid_df = valid_df.drop(columns=[\"level_group\"])\n",
        "\n",
        "      # Select the labels for the related q_no.\n",
        "\n",
        "      train_labels = labels.loc[labels.q==q_no].set_index('session').loc[train_users]\n",
        "      valid_labels = labels.loc[labels.q==q_no].set_index('session').loc[valid_users]\n",
        "\n",
        "      valid_labels = valid_labels['correct']\n",
        "\n",
        "      sub_model_number = train_sub_models(train_df.copy(),train_users.copy(),train_labels.copy(),q_no)\n",
        "      model_per_question.append(sub_model_number)\n",
        "\n",
        "  for q_no in range(1,19):\n",
        "    if q_no<=3: grp = '0-4'\n",
        "    elif q_no<=13: grp = '5-12'\n",
        "    elif q_no<=22: grp = '13-22'\n",
        "    for model_number in range(model_per_question[q_no-1]):\n",
        "      model_path = f'/content/drive/MyDrive/9417project/models/SVM_models/model_{grp}_{q_no}_sub{model_number}.joblib'\n",
        "      model = job.load(model_path)\n",
        "      valid_pred = model.predict(valid_df)\n",
        "      valid_pred_proba = model.predict_proba(valid_df)[:, 1]\n",
        "      prediction_df.loc[valid_users, q_no-1] += (valid_pred_proba/model_per_question[q_no-1]).flatten()\n",
        "\n",
        "  true_df = pd.DataFrame(data=np.zeros((len(VALID_USER_LIST),18)), index=VALID_USER_LIST)\n",
        "  for i in range(18):\n",
        "      # Get the true labels.\n",
        "      tmp = labels.loc[labels.q == i+1].set_index('session').loc[VALID_USER_LIST]\n",
        "      true_df[i] = tmp.correct.values\n",
        "\n",
        "  max_score = 0; best_threshold = 0\n",
        "  # loop through to find best threashold\n",
        "  for threshold in np.arange(0.4,0.8,0.01):\n",
        "      metric = tf.keras.metrics.F1Score(average=\"macro\",threshold=threshold)\n",
        "      y_true = tf.one_hot(true_df.values.reshape((-1)), depth=2)\n",
        "      y_pred = tf.one_hot((prediction_df.values.reshape((-1))>threshold).astype('int'), depth=2)\n",
        "      metric.update_state(y_true, y_pred)\n",
        "      f1_score = metric.result().numpy()\n",
        "      if f1_score > max_score:\n",
        "          max_score = f1_score\n",
        "          best_threshold = threshold\n",
        "          best_pred = y_pred\n",
        "\n",
        "  print(\"threshold \", best_threshold, \"\\tF1 score \", max_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "h4Pj_rmZS_xo"
      },
      "outputs": [],
      "source": [
        "# for q_no in range(1,19):\n",
        "#   if q_no<=3: grp = '0-4'\n",
        "#   elif q_no<=13: grp = '5-12'\n",
        "#   elif q_no<=22: grp = '13-22'\n",
        "\n",
        "#   # adding prediction probability from all sub_model\n",
        "#   for model_number in range(model_per_question[q_no-1]):\n",
        "#     model_path = f'/content/drive/MyDrive/9417project/models/SVM_models/model_{grp}_{q_no}_sub{model_number}.joblib'\n",
        "#     model = job.load(model_path)\n",
        "#     valid_pred = model.predict(valid_df)\n",
        "#     valid_pred_proba = model.predict_proba(valid_df)[:, 1]\n",
        "#     prediction_df.loc[valid_users, q_no-1] += (valid_pred_proba/model_per_question[q_no-1]).flatten()\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "GMCh7fZZD2Fa"
      },
      "outputs": [],
      "source": [
        "\n",
        "# To save prediction file to local for easy access later #\n",
        "file_path ='/content/drive/MyDrive/9417project/predictions/SVM_pred.npy'\n",
        "\n",
        "np.save(file_path,prediction_df)\n",
        "loaded_array = np.load(file_path,allow_pickle=True)\n",
        "#prediction_df = np.load(file_path,allow_pickle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "ne6MKhHFwJPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4180238b-68f2-477e-b4e4-9f81ceb8cfc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                    0    1    2    3    4    5    6    7    8    9    10   11  \\\n",
            "session_id                                                                      \n",
            "20090313091715820  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "20090313571836404  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "20090314035813970  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "20090314363702160  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "20090315170769824  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "...                ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "21020214413837144  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "21020214491545340  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "21020214510799336  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "21020214532330784  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "21020214552027400  1.0  1.0  1.0  1.0  0.0  1.0  1.0  0.0  1.0  0.0  1.0  1.0   \n",
            "\n",
            "                    12   13   14   15   16   17  \n",
            "session_id                                       \n",
            "20090313091715820  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "20090313571836404  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "20090314035813970  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "20090314363702160  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "20090315170769824  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "...                ...  ...  ...  ...  ...  ...  \n",
            "21020214413837144  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "21020214491545340  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "21020214510799336  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "21020214532330784  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "21020214552027400  0.0  1.0  0.0  1.0  1.0  1.0  \n",
            "\n",
            "[3848 rows x 18 columns]\n",
            "question 1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.00      0.00      1111\n",
            "           1       0.71      1.00      0.83      2737\n",
            "\n",
            "    accuracy                           0.71      3848\n",
            "   macro avg       0.61      0.50      0.42      3848\n",
            "weighted avg       0.65      0.71      0.59      3848\n",
            "\n",
            "question 2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        76\n",
            "           1       0.98      1.00      0.99      3772\n",
            "\n",
            "    accuracy                           0.98      3848\n",
            "   macro avg       0.49      0.50      0.50      3848\n",
            "weighted avg       0.96      0.98      0.97      3848\n",
            "\n",
            "question 3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       247\n",
            "           1       0.94      1.00      0.97      3601\n",
            "\n",
            "    accuracy                           0.94      3848\n",
            "   macro avg       0.47      0.50      0.48      3848\n",
            "weighted avg       0.88      0.94      0.90      3848\n",
            "\n",
            "question 4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.01      0.02       802\n",
            "           1       0.79      1.00      0.88      3046\n",
            "\n",
            "    accuracy                           0.79      3848\n",
            "   macro avg       0.60      0.50      0.45      3848\n",
            "weighted avg       0.71      0.79      0.70      3848\n",
            "\n",
            "question 5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      1.00      0.63      1787\n",
            "           1       1.00      0.00      0.00      2061\n",
            "\n",
            "    accuracy                           0.46      3848\n",
            "   macro avg       0.73      0.50      0.32      3848\n",
            "weighted avg       0.75      0.46      0.29      3848\n",
            "\n",
            "question 6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       938\n",
            "           1       0.76      1.00      0.86      2910\n",
            "\n",
            "    accuracy                           0.76      3848\n",
            "   macro avg       0.38      0.50      0.43      3848\n",
            "weighted avg       0.57      0.76      0.65      3848\n",
            "\n",
            "question 7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.01      0.01      1087\n",
            "           1       0.72      1.00      0.84      2761\n",
            "\n",
            "    accuracy                           0.72      3848\n",
            "   macro avg       0.59      0.50      0.42      3848\n",
            "weighted avg       0.65      0.72      0.60      3848\n",
            "\n",
            "question 8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.98      0.56      1520\n",
            "           1       0.45      0.01      0.02      2328\n",
            "\n",
            "    accuracy                           0.39      3848\n",
            "   macro avg       0.42      0.50      0.29      3848\n",
            "weighted avg       0.43      0.39      0.23      3848\n",
            "\n",
            "question 9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1070\n",
            "           1       0.72      1.00      0.84      2778\n",
            "\n",
            "    accuracy                           0.72      3848\n",
            "   macro avg       0.36      0.50      0.42      3848\n",
            "weighted avg       0.52      0.72      0.61      3848\n",
            "\n",
            "question 10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67      1932\n",
            "           1       1.00      0.00      0.00      1916\n",
            "\n",
            "    accuracy                           0.50      3848\n",
            "   macro avg       0.75      0.50      0.33      3848\n",
            "weighted avg       0.75      0.50      0.34      3848\n",
            "\n",
            "question 11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.38      0.00      0.01      1382\n",
            "           1       0.64      1.00      0.78      2466\n",
            "\n",
            "    accuracy                           0.64      3848\n",
            "   macro avg       0.51      0.50      0.39      3848\n",
            "weighted avg       0.55      0.64      0.50      3848\n",
            "\n",
            "question 12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       566\n",
            "           1       0.85      1.00      0.92      3282\n",
            "\n",
            "    accuracy                           0.85      3848\n",
            "   macro avg       0.43      0.50      0.46      3848\n",
            "weighted avg       0.73      0.85      0.79      3848\n",
            "\n",
            "question 13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.84      2802\n",
            "           1       0.25      0.00      0.00      1046\n",
            "\n",
            "    accuracy                           0.73      3848\n",
            "   macro avg       0.49      0.50      0.42      3848\n",
            "weighted avg       0.60      0.73      0.61      3848\n",
            "\n",
            "question 14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.01      0.02      1195\n",
            "           1       0.69      1.00      0.82      2653\n",
            "\n",
            "    accuracy                           0.69      3848\n",
            "   macro avg       0.85      0.50      0.42      3848\n",
            "weighted avg       0.79      0.69      0.57      3848\n",
            "\n",
            "question 15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.52      1.00      0.69      2010\n",
            "           1       1.00      0.00      0.00      1838\n",
            "\n",
            "    accuracy                           0.52      3848\n",
            "   macro avg       0.76      0.50      0.34      3848\n",
            "weighted avg       0.75      0.52      0.36      3848\n",
            "\n",
            "question 16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.01      0.01      1035\n",
            "           1       0.73      1.00      0.85      2813\n",
            "\n",
            "    accuracy                           0.73      3848\n",
            "   macro avg       0.80      0.50      0.43      3848\n",
            "weighted avg       0.77      0.73      0.62      3848\n",
            "\n",
            "question 17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1224\n",
            "           1       0.68      1.00      0.81      2624\n",
            "\n",
            "    accuracy                           0.68      3848\n",
            "   macro avg       0.34      0.50      0.41      3848\n",
            "weighted avg       0.46      0.68      0.55      3848\n",
            "\n",
            "question 18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       200\n",
            "           1       0.95      1.00      0.97      3648\n",
            "\n",
            "    accuracy                           0.95      3848\n",
            "   macro avg       0.47      0.50      0.49      3848\n",
            "weighted avg       0.90      0.95      0.92      3848\n",
            "\n"
          ]
        }
      ],
      "source": [
        "## Optional running from this point ##\n",
        "# get individual F1 for each question\n",
        "prediction_df_label = prediction_df\n",
        "print(prediction_df_label)\n",
        "\n",
        "for i in range(18):\n",
        "  prediction = prediction_df_label[i].values\n",
        "  for j in range(len(prediction)):\n",
        "    if prediction[j] >= best_threshold:\n",
        "      prediction[j] = True\n",
        "    else: prediction[j] = False\n",
        "  zero_division  =   list(set(list(true_df[i].values)) - set(prediction))\n",
        "\n",
        "  if len(zero_division)==1:\n",
        "    report = classification_report(list(true_df[i].values),prediction,zero_division = int(zero_division[0]))\n",
        "  else:\n",
        "    report = classification_report(list(true_df[i].values),prediction)\n",
        "  print(f'question {i+1}')\n",
        "  print(report)\n",
        "\n",
        "  #report_path = f'/content/drive/MyDrive/9417project/report/classification_report{i+1}.txt'\n",
        "  #with open(report_path, 'w') as file:\n",
        "      #file.write(report)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}